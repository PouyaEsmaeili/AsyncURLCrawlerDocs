Search.setIndex({"docnames": ["AsyncURLCrawler", "Disclaimer", "Installation", "Introduction", "License", "Usage", "index", "modules"], "filenames": ["AsyncURLCrawler.rst", "Disclaimer.rst", "Installation.rst", "Introduction.rst", "License.rst", "Usage.rst", "index.rst", "modules.rst"], "titles": ["AsyncURLCrawler package", "Disclaimer", "Installation", "Introduction", "License", "Usage", "Welcome to AsyncURLCrawler\u2019s documentation!", "src"], "terms": {"class": 0, "seed_url": [0, 5], "list": [0, 5], "str": 0, "deep": [0, 5], "bool": 0, "fals": [0, 5], "exact": [0, 5], "true": [0, 5], "delai": [0, 5], "float": 0, "0": [0, 5], "base": 0, "object": 0, "extract": 0, "url": [0, 3], "from": [0, 1, 4, 5], "target": 0, "websit": 0, "us": [0, 1, 2, 3, 4, 5], "breadth": 0, "first": [0, 3], "search": [0, 6], "bf": [0, 3], "algorithm": [0, 3], "arg": 0, "initi": 0, "start": 0, "crawl": [0, 5, 7], "must": 0, "follow": [0, 2, 3, 4], "valid": 0, "pattern": 0, "e": 0, "g": 0, "http": [0, 5], "exampl": 0, "com": 0, "instanc": 0, "respons": [0, 1], "fetch": 0, "given": 0, "option": 0, "If": 0, "all": [0, 4], "discov": 0, "recurs": 0, "default": 0, "Not": 0, "recommend": 0, "due": 0, "high": 0, "resourc": 0, "usag": [0, 6], "restrict": [0, 4], "same": 0, "subdomain": 0, "seed": 0, "ignor": 0, "i": [0, 4, 5], "time": 0, "second": 0, "between": 0, "request": 0, "prevent": 0, "overwhelm": 0, "server": 0, "async": [0, 5], "dict": 0, "asynchron": 0, "return": 0, "A": [0, 4], "dictionari": 0, "where": 0, "each": 0, "kei": [0, 5], "valu": 0, "set": 0, "visit": 0, "get_visited_url": [0, 7], "yielded_crawl": [0, 7], "yield": 0, "delay_start": [0, 5], "1": [0, 5], "max_retri": [0, 5], "int": 0, "5": [0, 5], "request_timeout": [0, 5], "user_ag": [0, 5], "mozilla": [0, 5], "pars": 0, "its": 0, "html": 0, "content": 0, "tag": 0, "implement": 0, "exponenti": 0, "backoff": 0, "retri": 0, "fail": 0, "strategi": 0, "maximum": 0, "number": 0, "attempt": 0, "timeout": 0, "user": 0, "agent": 0, "string": 0, "header": 0, "probe": [0, 7], "an": [0, 4], "failur": 0, "The": [0, 1, 4], "empti": 0, "after": 0, "reset": [0, 7], "state": 0, "new": 0, "call": 0, "befor": 0, "except": 0, "invalidurl": [0, 7], "rais": 0, "when": 0, "doe": 0, "match": 0, "expect": 0, "invalid": 0, "attribut": 0, "messag": 0, "explan": 0, "error": 0, "have_exact_domain": [0, 7], "url1": 0, "url2": 0, "check": [0, 3], "two": 0, "share": 0, "domain": [0, 3], "both": 0, "have": 0, "includ": [0, 4], "have_exact_subdomain": [0, 7], "suffix": 0, "normalize_url": [0, 7], "base_url": 0, "convert": 0, "rel": 0, "absolut": 0, "normal": 0, "which": 0, "mai": 0, "resolv": 0, "against": 0, "validate_url": [0, 7], "singl": 0, "predefin": 0, "regex": 0, "otherwis": [0, 4], "none": 0, "ani": [0, 1, 4], "your": 1, "own": 1, "risk": 1, "author": [1, 4], "contributor": 1, "ar": 1, "misus": 1, "consequ": 1, "result": [1, 5], "thi": [1, 2, 4], "project": 1, "To": [2, 3], "modul": [2, 6, 7], "command": 2, "pip": 2, "asyncurlcrawl": [2, 3, 5, 7], "specif": 2, "version": 2, "navig": 3, "through": 3, "web": 3, "page": [3, 6], "concurr": 3, "hyperlink": 3, "collect": 3, "make": 3, "robot": 3, "txt": 3, "github": 3, "pypi": 3, "mit": 4, "copyright": 4, "c": 4, "2023": 4, "pouya": [4, 5], "esmaeili": 4, "permiss": 4, "herebi": 4, "grant": 4, "free": 4, "charg": 4, "person": 4, "obtain": 4, "copi": 4, "softwar": 4, "associ": 4, "document": 4, "file": [4, 5], "deal": 4, "without": 4, "limit": 4, "right": 4, "modifi": 4, "merg": 4, "publish": 4, "distribut": 4, "sublicens": 4, "sell": 4, "permit": 4, "whom": 4, "furnish": 4, "do": 4, "so": 4, "subject": 4, "condit": 4, "abov": 4, "notic": 4, "shall": 4, "substanti": 4, "portion": 4, "THE": 4, "provid": 4, "AS": 4, "warranti": 4, "OF": 4, "kind": 4, "express": 4, "OR": 4, "impli": 4, "BUT": 4, "NOT": 4, "TO": 4, "merchant": 4, "fit": 4, "FOR": 4, "particular": 4, "purpos": 4, "AND": 4, "noninfring": 4, "IN": 4, "NO": 4, "event": 4, "holder": 4, "BE": 4, "liabl": 4, "claim": 4, "damag": 4, "other": 4, "liabil": 4, "whether": 4, "action": 4, "contract": 4, "tort": 4, "aris": 4, "out": 4, "connect": 4, "WITH": 4, "here": 5, "simpl": 5, "python": 5, "script": 5, "show": 5, "how": 5, "packag": [5, 6, 7], "import": 5, "asyncio": 5, "o": 5, "parser": [5, 6, 7], "crawler": [5, 6, 7], "yaml": 5, "def": 5, "main": 5, "ir": 5, "await": 5, "open": 5, "path": 5, "join": 5, "output_path": 5, "w": 5, "dump": 5, "__name__": 5, "__main__": 5, "run": 5, "introduct": 6, "instal": 6, "url_util": [6, 7], "disclaim": 6, "licens": 6, "index": 6}, "objects": {"AsyncURLCrawler": [[0, 0, 0, "-", "crawler"], [0, 0, 0, "-", "parser"], [0, 0, 0, "-", "url_utils"]], "AsyncURLCrawler.crawler": [[0, 1, 1, "", "Crawler"]], "AsyncURLCrawler.crawler.Crawler": [[0, 2, 1, "", "crawl"], [0, 2, 1, "", "get_visited_urls"], [0, 2, 1, "", "yielded_crawl"]], "AsyncURLCrawler.parser": [[0, 1, 1, "", "Parser"]], "AsyncURLCrawler.parser.Parser": [[0, 2, 1, "", "probe"], [0, 2, 1, "", "reset"]], "AsyncURLCrawler.url_utils": [[0, 3, 1, "", "InvalidURL"], [0, 4, 1, "", "have_exact_domain"], [0, 4, 1, "", "have_exact_subdomain"], [0, 4, 1, "", "normalize_url"], [0, 4, 1, "", "validate_url"], [0, 4, 1, "", "validate_urls"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:exception", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "exception", "Python exception"], "4": ["py", "function", "Python function"]}, "titleterms": {"asyncurlcrawl": [0, 6], "packag": 0, "crawler": 0, "modul": 0, "parser": 0, "url_util": 0, "disclaim": 1, "instal": 2, "introduct": 3, "licens": 4, "usag": 5, "welcom": 6, "": 6, "document": 6, "content": 6, "indic": 6, "tabl": 6, "src": 7}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx": 60}, "alltitles": {"AsyncURLCrawler package": [[0, "asyncurlcrawler-package"]], "AsyncURLCrawler.crawler module": [[0, "module-AsyncURLCrawler.crawler"]], "AsyncURLCrawler.parser module": [[0, "module-AsyncURLCrawler.parser"]], "AsyncURLCrawler.url_utils module": [[0, "module-AsyncURLCrawler.url_utils"]], "Disclaimer": [[1, "disclaimer"]], "Installation": [[2, "installation"]], "Introduction": [[3, "introduction"]], "License": [[4, "license"]], "Usage": [[5, "usage"]], "Welcome to AsyncURLCrawler\u2019s documentation!": [[6, "welcome-to-asyncurlcrawler-s-documentation"]], "Contents:": [[6, null]], "Indices and tables": [[6, "indices-and-tables"]], "src": [[7, "src"]]}, "indexentries": {"asyncurlcrawler.crawler": [[0, "module-AsyncURLCrawler.crawler"]], "asyncurlcrawler.parser": [[0, "module-AsyncURLCrawler.parser"]], "asyncurlcrawler.url_utils": [[0, "module-AsyncURLCrawler.url_utils"]], "crawler (class in asyncurlcrawler.crawler)": [[0, "AsyncURLCrawler.crawler.Crawler"]], "invalidurl": [[0, "AsyncURLCrawler.url_utils.InvalidURL"]], "parser (class in asyncurlcrawler.parser)": [[0, "AsyncURLCrawler.parser.Parser"]], "crawl() (asyncurlcrawler.crawler.crawler method)": [[0, "AsyncURLCrawler.crawler.Crawler.crawl"]], "get_visited_urls() (asyncurlcrawler.crawler.crawler method)": [[0, "AsyncURLCrawler.crawler.Crawler.get_visited_urls"]], "have_exact_domain() (in module asyncurlcrawler.url_utils)": [[0, "AsyncURLCrawler.url_utils.have_exact_domain"]], "have_exact_subdomain() (in module asyncurlcrawler.url_utils)": [[0, "AsyncURLCrawler.url_utils.have_exact_subdomain"]], "module": [[0, "module-AsyncURLCrawler.crawler"], [0, "module-AsyncURLCrawler.parser"], [0, "module-AsyncURLCrawler.url_utils"]], "normalize_url() (in module asyncurlcrawler.url_utils)": [[0, "AsyncURLCrawler.url_utils.normalize_url"]], "probe() (asyncurlcrawler.parser.parser method)": [[0, "AsyncURLCrawler.parser.Parser.probe"]], "reset() (asyncurlcrawler.parser.parser method)": [[0, "AsyncURLCrawler.parser.Parser.reset"]], "validate_url() (in module asyncurlcrawler.url_utils)": [[0, "AsyncURLCrawler.url_utils.validate_url"]], "validate_urls() (in module asyncurlcrawler.url_utils)": [[0, "AsyncURLCrawler.url_utils.validate_urls"]], "yielded_crawl() (asyncurlcrawler.crawler.crawler method)": [[0, "AsyncURLCrawler.crawler.Crawler.yielded_crawl"]]}})